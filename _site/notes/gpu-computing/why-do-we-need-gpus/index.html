<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" />
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Why did we need GPUs</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Why did we need GPUs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introduction Moores law is the prediction that the numbers of transistors per unit area would double every 18-24 months." />
<meta property="og:description" content="Introduction Moores law is the prediction that the numbers of transistors per unit area would double every 18-24 months." />
<link rel="canonical" href="http://localhost:4000/notes/gpu-computing/why-do-we-need-gpus/" />
<meta property="og:url" content="http://localhost:4000/notes/gpu-computing/why-do-we-need-gpus/" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-19T14:45:18+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Why did we need GPUs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-19T14:45:18+01:00","datePublished":"2025-08-19T14:45:18+01:00","description":"Introduction Moores law is the prediction that the numbers of transistors per unit area would double every 18-24 months.","headline":"Why did we need GPUs","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/notes/gpu-computing/why-do-we-need-gpus/"},"url":"http://localhost:4000/notes/gpu-computing/why-do-we-need-gpus/"}</script>
<!-- End Jekyll SEO tag -->

    <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global',
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

  </head>
  <body>
    <div class="pagecontents">
        <div class="navbar">
  
    <a href="/">
        HOME
    </a>
  
    <a href="/blog/">
        BLOG
    </a>
  
    <a href="/projects/">
        PROJECTS
    </a>
  
    <a href="/notes/">
        NOTES
    </a>
  
</div>

        <!-- <h1 class="page-title">Why did we need GPUs</h1> -->
        <div class="container">
            <h1 class="page-title">Why did we need GPUs</h1>
<h1 id="introduction">Introduction</h1>
<p><strong>Moores law</strong> is the prediction that the numbers of <strong>transistors</strong> per unit area
would double every <strong>18-24 months</strong>.</p>

<p>This was been true until <strong>2005</strong>.</p>

<p>The transistors are getting harder to make smaller due to the physical limitations.<br />
[look up] why is it actually getting harder? -&gt; physics was an issue, heat became too 
high to realistically rely on cooling to solve the problem</p>

<p>When they get smaller it is easier to switch them on and off faster, so we can 
increase the clock <strong>frequency</strong> faster.</p>

<p>The <strong>frequency (clock rate)</strong> followed the same trend as a result but this lasted only 
until 2005.</p>

<p>Even if the transistors were doubling we stopped trying to increase the frequency
because it takes more power to do this. Burning more power generates more heat thus 
needing cooling or the CPU would begin melting.</p>

<p>There was a bottleneck because of the cooling technology we had.</p>

<p>Single thread performance also started to stagnate but because of compiler advancements
and improvements in architecture there were still some improvements.
[look up] speculative execution, branch prediction, out of order execution</p>

<p>Because the single thread performance was stagnating but we were still getting more 
transistors. We started to use extra transistors to make the <strong>CPU</strong> cores more
complex, better at single threaded performance, we hit physical and architectural
walls (power, <strong>ILP (Instruction-Level Parallelism)</strong>, heat). So we began to use those
transistors to build many simpler <strong>cores</strong> with more <strong>ALUs</strong>, focused on parallelism
rather than per-core complexity.</p>

<p>This all happened at around <strong>2005</strong>.</p>

<p>Before the slow down in single thread performance, it was possible to just see massive
performance gains by running an older program on a new processor. However, to now see
performance gains in software it was now required to update programs to take advantage
of parallel processing.</p>

<h2 id="design-approaches">Design approaches</h2>
<p><strong>Latency-Oriented Design</strong>: minimize the time it takes for a single task<br />
<strong>Throughput-Oriented Design</strong>: maximise the number of task that can be performed in 
                              a given time frame</p>

<p><strong>CPU</strong>: Latency-Oriented Design</p>
<ul>
  <li>has few powerful <strong>ALU</strong> to reduce operation latency</li>
  <li>large <strong>caches</strong> reduce the missrate of the CPU,</li>
  <li>sophisticated <strong>control units</strong> for branch prediction to reduce control hazards
    <ul>
      <li>data forwarding to reduce data hazards</li>
      <li>out-of-order operation to reduce latency</li>
    </ul>
  </li>
</ul>

<p>[look up] n-bit multi cycle and single cycle
          why do smaller ALUs give higher latency for operations?</p>

<p><strong>GPU</strong>: Throughput-Oriented Design</p>
<ul>
  <li>ALU are much smaller and have higher latency but have higher throughput. 
[look up] Heavily pipelined for further throughput.</li>
  <li>small caches so we can dedicate more area in the silicon to compute
    <ul>
      <li>memory access operations take longer as a result</li>
    </ul>
  </li>
  <li>simpler control units so we have more area dedicated to computation</li>
</ul>

<p>minimize stalls in the pipeline with scheduling instructions with compiler techniques.</p>

<p>On the hardware side we can do out-of-order ROB [look up]
they can also do <strong>multithreading</strong> to hide short latency</p>
<ul>
  <li>use the same <strong>core</strong> to execute multiple <strong>threads</strong></li>
  <li><strong>hyperthreading</strong> commonly uses 2 threads running at the same time in the same 
core</li>
  <li>CPU have a modest amount of multithreading</li>
</ul>

<p>On the GPU we have a massive number of threads to hide the high latency</p>
<ul>
  <li>many more cores means more threads that can be used</li>
  <li>more threads can be used on the same core, instead of just 2 we could use 32</li>
</ul>

<p>CPU have high clock frequency while GPU have moderate clock frequency</p>

<h2 id="what-is-a-gpu">What is a GPU</h2>
<p>In graphics we donâ€™t care about the speed at which we can render 1 pixel, we care more
about rendering as many pixels as possible at the same time.</p>

<p>People realised that <code class="language-plaintext highlighter-rouge">GPUs</code> althought built for graphics, were actually great at 
general purpose computing as well. However, before 2007 there were only graphics APIs
to program on <code class="language-plaintext highlighter-rouge">GPU</code> like openGL.</p>

<p>So people had to reformulate their computation as functions that operate on pixels to 
do their operations.</p>

<p>NVIDIA then released <code class="language-plaintext highlighter-rouge">CUDA</code> as a result. A programming interface to use the power of 
<code class="language-plaintext highlighter-rouge">GPUs</code> in a general purpose way. 
This still required extensions to the <code class="language-plaintext highlighter-rouge">GPU architecture</code>.</p>

<p>2007 marks the beginning of the modern computing era.</p>

<h2 id="why-did-gpus-succeed">Why did GPUs succeed?</h2>
<p>Chips are very expensives to build and require a large volume of sales to balance 
the costs.</p>
<ul>
  <li>this makes the chip market hard to get into and succeed in</li>
  <li>when parallel computing becamse mainstream, <code class="language-plaintext highlighter-rouge">GPUs</code> were already being used in the 
gaming sector so it gave them a large head start compared to other potential 
    massively parallel accelerators</li>
</ul>

<p>One issue is that because the gaming sector is the largest market share for <code class="language-plaintext highlighter-rouge">GPUs</code>,
if there is a new advancement that could improve performance in scientefic computing 
but would negatively impact the performance in gaming, the likelyhood of the
manufacturer going ahead with it is low.</p>

<p>[look up] tenstorrent</p>

<h2 id="resources">Resources</h2>
<ul>
  <li><a href="https://www.youtube.com/watch?v=4pkbXmE4POc&amp;list=PLRRuQYjFhpmubuwx-w8X964ofVkW1T8O4&amp;index=1">PMPP lecture 1</a></li>
</ul>


        </div>
    </div>
  </body>
</html>
